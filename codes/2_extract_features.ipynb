{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Feature Extraction\n",
    "\n",
    "This notebook reads a set of images stored in a directory and extracts image features from a pre-trained network with FastAI. Required fastai==2.5.2 with CUDA enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import shutil, timm, time\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from timm import create_model\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader from dataframe\n",
    "def create_dls(df, size=224, x_col=\"path\", y_col=\"labels\", col_splitter=True, bs=128):\n",
    "  item_tfms = [Resize(size)]\n",
    "  batch_tfms = []\n",
    "  if col_splitter:\n",
    "    splitter = ColSplitter(\"is_valid\")\n",
    "  else:\n",
    "    splitter = RandomSplitter(valid_pct=0.0, seed=36)\n",
    "  # Create datablock\n",
    "  rocks = DataBlock(\n",
    "              blocks = (ImageBlock, CategoryBlock),\n",
    "              get_x = ColReader(x_col),\n",
    "              splitter = splitter,\n",
    "              get_y = ColReader(y_col),\n",
    "              item_tfms = item_tfms,\n",
    "              batch_tfms = batch_tfms\n",
    "          )\n",
    "  dls = rocks.dataloaders(df,bs=bs, shuffle=False, drop_last=False)\n",
    "  return dls\n",
    "\n",
    "# define input and output functions\n",
    "def get_output(module, input_value, output):\n",
    "  return output.flatten(1)\n",
    "def get_input(module, input_value, output):\n",
    "  return list(input_value)[0]\n",
    "\n",
    "# get layer named: name\n",
    "def get_named_module_from_model(model, name):\n",
    "  for n, m in model.named_modules():\n",
    "    if n == name:\n",
    "      return m\n",
    "  return None\n",
    "\n",
    "# hook to last fully connect layer\n",
    "class Hook():\n",
    "  \"Create a hook on `m` with `hook_func`.\"\n",
    "  def __init__(self, m:nn.Module, hook_func, is_forward:bool=True, detach:bool=True):\n",
    "    self.hook_func,self.detach,self.stored = hook_func,detach,None\n",
    "    f = m.register_forward_hook if is_forward else m.register_backward_hook\n",
    "    self.hook = f(self.hook_fn)\n",
    "    self.removed = False\n",
    "\n",
    "  def hook_fn(self, module:nn.Module, input, output):\n",
    "    \"Applies `hook_func` to `module`, `input`, `output`.\"\n",
    "    if self.detach:\n",
    "      input  = (o.detach() for o in input ) if is_listy(input ) else input.detach()\n",
    "      output = (o.detach() for o in output) if is_listy(output) else output.detach()\n",
    "    self.stored = self.hook_func(module, input, output)\n",
    "\n",
    "  def remove(self):\n",
    "    \"Remove the hook from the model.\"\n",
    "    if not self.removed:\n",
    "      self.hook.remove()\n",
    "      self.removed=True\n",
    "\n",
    "  def __enter__(self, *args): return self\n",
    "  def __exit__(self, *args): self.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data & Set Output Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set output pickle and csv paths\n",
    "csv_path = r'../data/processed2/feats_MSDP_features.csv'\n",
    "pkl_path = r'../data/processed2/feats_MSDP_features.pkl'\n",
    "\n",
    "# set paths to image tiles\n",
    "img_path = r'../data/processed2/tiles'\n",
    "\n",
    "# read images paths into data frame \n",
    "sublists= [[os.path.join(i[0], j) for j in i[2] if j.endswith('.jpg') ] for i in os.walk(img_path)]\n",
    "filelist = np.array([item for sublist in sublists for item in sublist])\n",
    "df = pd.DataFrame()\n",
    "df['img'] = [x.split('/')[-1] for x in filelist]\n",
    "df['path'] = [os.path.join(img_path, x) for x in filelist]\n",
    "df['labels'] = [x.split('/')[8] for x in filelist]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define batch size and create a dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define batch size\n",
    "bs = 4\n",
    "\n",
    "# create dataloader for feature extraction\n",
    "dls = create_dls(df,col_splitter=False, bs=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model\n",
    "\n",
    "We use timm to get SoTA trained model\n",
    "<https://github.com/rwightman/pytorch-image-models/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list model names\n",
    "model_names = timm.list_models('*efficientnetv2*',pretrained=True)\n",
    "# pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished prepare model!\n"
     ]
    }
   ],
   "source": [
    "# define body\n",
    "base_model_name = 'efficientnetv2_rw_s'\n",
    "\n",
    "# get the body\n",
    "body = create_model(base_model_name, pretrained=True, in_chans=3, num_classes=0)\n",
    "new_body = nn.Sequential(*list(body.children())[:-2])\n",
    "nf = num_features_model(nn.Sequential(*body.children())) \n",
    "\n",
    "# define head and model\n",
    "head = create_head(nf, dls.c)\n",
    "model = nn.Sequential(new_body, head)\n",
    "\n",
    "# initialise weight and create learner\n",
    "apply_init(model[1], nn.init.kaiming_normal_)\n",
    "learner = Learner(dls, model, loss_func=LabelSmoothingCrossEntropy(), metrics=accuracy)\n",
    "\n",
    "# get model and copy it to GPU\n",
    "model = learner.model\n",
    "model.cuda()\n",
    "linear_output_layer = get_named_module_from_model(model, \"1.4\")\n",
    "print(\"Finished prepare model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature map ...\n",
      "137.40247082710266 secs for 12800 images\n",
      "135.29288482666016 secs for 12800 images\n",
      "141.77030682563782 secs for 12800 images\n",
      "157.8251769542694 secs for 12800 images\n",
      "163.55647158622742 secs for 12800 images\n",
      "146.89552187919617 secs for 12800 images\n",
      "145.5284366607666 secs for 12800 images\n",
      "144.8761203289032 secs for 12800 images\n",
      "147.19988894462585 secs for 12800 images\n",
      "145.5785939693451 secs for 12800 images\n",
      "148.4882583618164 secs for 12800 images\n",
      "146.3279824256897 secs for 12800 images\n",
      "145.01856541633606 secs for 12800 images\n",
      "145.18116807937622 secs for 12800 images\n",
      "Total processing time:  2158.337628364563\n"
     ]
    }
   ],
   "source": [
    "# run feature extraction procedure\n",
    "img_repr_map = {}\n",
    "start_time = time.time()\n",
    "print(\"Generating feature map ...\")\n",
    "total = 0\n",
    "with Hook(linear_output_layer, get_output, True, True) as hook:\n",
    "    start = time.time()\n",
    "    for i, (xb, yb) in enumerate(dls[0]):\n",
    "        cur_bs = xb.shape[0]\n",
    "        end = i*bs + cur_bs\n",
    "        img_ids = dls[0].items[i*bs:end].path.values\n",
    "        result = model.eval()(xb)\n",
    "        img_reprs = hook.stored.cpu().numpy()\n",
    "        img_reprs = img_reprs.reshape(cur_bs, -1)\n",
    "        for j in range(cur_bs):\n",
    "            img_repr_map[img_ids[j]] = img_reprs[j]\n",
    "        if(len(img_repr_map) % 12800 == 0):\n",
    "            end = time.time()\n",
    "            print(f'{end-start} secs for 12800 images')\n",
    "            start = end\n",
    "\n",
    "# place features in a data frame\n",
    "print(\"Total processing time: \", time.time()-start_time)\n",
    "df_feature = pd.DataFrame(img_repr_map.items(), columns=['path', 'feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save features to pickle and csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the feature data frame to pickle\n",
    "df_feature.to_pickle(pkl_path, protocol=4)\n",
    "\n",
    "# add prefix 'X' to features and save to csv\n",
    "df_wide = pd.DataFrame(df_feature[\"feature\"].to_list())\n",
    "df_wide = df_wide.add_prefix('X')\n",
    "df_wide.insert(0, \"path\", df_feature[\"path\"])\n",
    "df_wide.to_csv(csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('core_fusion')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ae034cbead4b5496d53e9e09bcd6c3551401adb133df0846d1cd3b92b5f34f9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
